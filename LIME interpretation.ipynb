{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LIME interpretation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPDKW3vWXeuxF3savW9OWUl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jMndhhPv25By"},"source":["!pip install transformers \n","!pip install lime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PNRy-s03CSM"},"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer, BertModel\n","from utils.models import bertCNN\n","import torch\n","from utils.data_processor import data_loader\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","from lime.lime_text import LimeTextExplainer\n","import matplotlib.pyplot as plt\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","\n","\n","class Prediction:\n","    def __init__(self, model_dir, model_path, do_lower_case):\n","        if model_path.startswith('bert'):\n","            pretrained_weights = 'bert-base-multilingual-cased'\n","        elif model_path.startswith('xlm'):\n","            pretrained_weights = 'xlm-roberta-base'\n","        else:\n","            raise ValueError('error path!')\n","        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_weights, do_lower_case=do_lower_case)\n","        if model_path.startswith('bert_cnn'):\n","            print('bert_cnn')\n","            embed_model = BertModel.from_pretrained(pretrained_weights)\n","            self.model = bertCNN(embed_model=embed_model, dropout=0.2, kernel_num=4, kernel_sizes=[3, 4, 5, 6], num_labels=3)\n","        else:\n","            print('sequence classification')\n","            self.model = AutoModelForSequenceClassification.from_pretrained(pretrained_weights,\n","                                                                       num_labels=3,\n","                                                                       output_attentions=False,\n","                                                                       output_hidden_states=False)\n","        self.device = 'cuda' if cuda.is_available() else 'cpu'\n","        self.model.load_state_dict(torch.load(os.path.join(model_dir, model_path)))\n","        self.model.to(self.device)\n","\n","    def convert_text_to_features(self, text):\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=150,\n","            pad_to_max_length=True,\n","            truncation=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","        ids = torch.tensor([ids], dtype=torch.long).to(device)\n","        mask = torch.tensor([mask], dtype=torch.long).to(device)\n","        token_type_ids = torch.tensor([token_type_ids], dtype=torch.long).to(device)\n","\n","        return ids, mask, token_type_ids\n","\n","    def predictor(self, texts):\n","        examples = []\n","        print(texts)\n","        for example in texts:\n","            examples.append(self.convert_text_to_features(example))\n","\n","        results = []\n","        for example in examples:\n","            with torch.no_grad():\n","                outputs = self.model(example[0], example[1], example[2])\n","                logits = outputs[0]\n","                logits = F.softmax(logits, dim=1)\n","                results.append(logits.cpu().detach().numpy()[0])\n","\n","        results_array = np.array(results)\n","        # print(results_array)\n","        return results_array\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1w2Eak8y3IAt"},"source":["from lime.lime_text import LimeTextExplainer\n","class_names = ['solidarity', 'anti-solidarity', 'other']\n","explainer = LimeTextExplainer(class_names=class_names)\n","\n","# pre-trained classifier model\n","model_dir = 'saved_models/saved_weights/ensemble_more'\n","model_name = 'xlm_finetune_mlm_8000steps+trans+auto_data_0.734_0.781.bin'\n","prediction = Prediction(model_dir=model_dir, model_path=model_name, do_lower_case=False)\n","\n","# use LIME to interpretate a tweet preidiction of the classifier model\n","example = \"Countries of south-eastern europe, do not let the migrants in your country. We will not take them this time. Good luck! #Greece #Macedonia #Serbia #Bosnia #Croatia #Hungary #Slovenia #Migration #HumanRightsRefugee #NeverAgain2015 #Turkey #Syria #refugee #RefugeesWelcome https://twitter.com/DerSteirische/status/1233868109045518337\"\n","exp = explainer.explain_instance(example, prediction.predictor, top_labels=1, num_samples=2500)\n","exp.show_in_notebook(text=example)"],"execution_count":null,"outputs":[]}]}